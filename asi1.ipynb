{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09e071e-1a23-473f-9ad4-ecdddf46a081",
   "metadata": {},
   "source": [
    "PMF (Probability Mass Function) is used for discrete random variables and gives the probability that the variable is exactly equal to a specific value.\n",
    "\n",
    "PDF (Probability Density Function) is used for continuous random variables and describes the likelihood of the variable taking on a specific value, with probabilities given by the area under the curve over intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be043aa-920f-4569-a220-6c8e5ca2d945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2582f435-02e3-4957-b2aa-0bc6b8f2a9a4",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability theory and statistics that describes the probability that a random variable takes on a value less than or equal to a specific value. The CDF is used for both discrete and continuous random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac34574-a0dd-4fc5-9e30-e2bb3cb0fda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "915295ec-b0db-4e90-abc6-e050e3192ca0",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a fundamental probability distribution in statistics and is often used to model various real-world situations due to its desirable properties and the Central Limit Theorem.\n",
    "\n",
    "Examples of Normal Distribution Usage\n",
    "\n",
    "Height of People: Human heights tend to follow a normal distribution, with most people clustered around the average height and fewer people at the extremes.\n",
    "\n",
    "Test Scores: Standardized test scores, such as the SAT or IQ tests, often follow a normal distribution, with most students scoring near the mean and fewer achieving very high or very low scores.\n",
    "\n",
    "Measurement Errors: When measuring a physical quantity, the errors due to precision limitations of the instrument or environmental conditions tend to be normally distributed around the true value.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean and the standard deviation .\n",
    "\n",
    "Mean (μ):\n",
    "\n",
    "The mean is the central location of the distribution. It determines where the peak of the bell curve is centered.\n",
    "\n",
    "Changing the mean shifts the entire distribution left or right on the horizontal axis without affecting its shape.\n",
    "\n",
    "Standard Deviation (σ):\n",
    "\n",
    "The standard deviation measures the spread or dispersion of the distribution. It determines the width of the bell curve.\n",
    "\n",
    "A smaller standard deviation results in a narrower and taller curve, indicating that the data points are clustered more closely around the mean.\n",
    "\n",
    "A larger standard deviation results in a wider and flatter curve, indicating that the data points are spread out more widely around the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88c35f-34d2-46f9-b3db-fcfad13c2802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe7a049-dc11-4aed-a429-e73d52acd0b3",
   "metadata": {},
   "source": [
    "Importance of Normal Distribution\n",
    "\n",
    "Central Limit Theorem (CLT): One of the most significant reasons for the importance of the normal distribution is the Central Limit Theorem. The CLT states that the sum (or average) of a large number of independent, identically distributed random variables tends to be normally distributed, regardless of the original distribution of the variables. This property makes the normal distribution a fundamental tool in inferential statistics.\n",
    "\n",
    "Simplicity and Mathematical Properties: The normal distribution is mathematically tractable. It has properties such as symmetry, which simplifies analysis and computations. Many statistical methods and tests are based on the assumption of normality due to these properties.\n",
    "\n",
    "Descriptive Statistics: Many natural and human-made phenomena approximate the normal distribution. This makes it a useful model for describing and understanding data in various fields.\n",
    "\n",
    "Basis for Statistical Inference: Many parametric statistical tests, confidence intervals, and regression models rely on the assumption that the data or residuals are normally distributed.\n",
    "\n",
    "Real-Life Examples of Normal Distribution\n",
    "\n",
    "Human Heights: Human heights in a population tend to follow a normal distribution. Most individuals are around the average height, with fewer individuals being extremely tall or short.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores are designed to follow a normal distribution with a mean of 100 and a standard deviation of 15. This ensures that about 68% of the population has an IQ between 85 and 115.\n",
    "\n",
    "Measurement Errors: Errors in physical measurements often follow a normal distribution. This occurs because the errors are the result of many small, independent factors.\n",
    "\n",
    "Daily Stock Returns: Over short time periods, the returns of stocks often follow a normal distribution. This assumption underlies many models in finance, such as the Black-Scholes option pricing model.\n",
    "\n",
    "Blood Pressure: In a large, healthy population, systolic blood pressure measurements typically follow a normal distribution. Most individuals have blood pressure near the average, with fewer individuals having significantly higher or lower blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84012eb6-769f-497c-9904-9afeefb127e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ac3f979-0f8d-4aec-bad5-ead9d3f694d5",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is one of the simplest and most fundamental probability distributions in statistics. It describes a random experiment with exactly two possible outcomes: success (with probability p) and failure (with probability 1−p).\n",
    "\n",
    "Example\n",
    "Consider flipping a fair coin:\n",
    "\n",
    "The outcome can be heads (success) with probability p=0.5.\n",
    "\n",
    "The outcome can be tails (failure) with probability 1−p=0.5.\n",
    "\n",
    "In this case, if we define X=1 for heads and X=0 for tails, \n",
    "X follows a Bernoulli distribution with p=0.5.\n",
    "\n",
    "Differences between Bernoulli and Binomial Distributions\n",
    "\n",
    "Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Considers a single trial.\n",
    "\n",
    "Binomial Distribution: Considers multiple (fixed number) of independent trials.\n",
    "\n",
    "Random Variable:\n",
    "\n",
    "Bernoulli Distribution: The random variable represents the outcome of a single trial (success or failure).\n",
    "\n",
    "Binomial Distribution: The random variable represents the number of successes in multiple trials.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "Bernoulli Distribution: Has one parameter p, the probability of success.\n",
    "\n",
    "Binomial Distribution: Has two parameters n (number of trials) and p (probability of success in each trial).\n",
    "\n",
    "Range of Values:\n",
    "\n",
    "Bernoulli Distribution: The random variable can take on values 0 or 1.\n",
    "\n",
    "Binomial Distribution: The random variable can take on values from 0 to n, where n is the number of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47de0c-15e8-446f-8126-d898524d31bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e2586da-dcb2-4274-bd23-69a6b9efd2ce",
   "metadata": {},
   "source": [
    "o calculate the probability that a randomly selected observation from a dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we can use the standard normal distribution. Given that the dataset is normally distributed, we need to find the Z-score for the value of 60 using the formula:\n",
    "\n",
    "Z=(X-μ)/σ = 60-50 / 10 = 1\n",
    "\n",
    "Next, we find the probability that a randomly selected observation will be greater than 60 by looking up the corresponding area to the right of the Z-score of 1 in the standard normal distribution table. Since the table typically provides probabilities to the left of the Z-score, we need to find the area to the left of 1 and then subtract it from 1 to get the area to the right.\n",
    "\n",
    "From the standard normal distribution table, the probability to the left of Z = 1 is approximately 0.8413. Therefore, the probability that a randomly selected observation will be greater than 60 is:\n",
    "\n",
    "𝑃(𝑋>60) = 1-P(Z<1) = 1-0.8413 = 0.1587\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e25e39-c33b-40d2-80cd-9020e61f937c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1234a16-70b3-49ee-87f2-7959f103014f",
   "metadata": {},
   "source": [
    "The uniform distribution is a type of probability distribution in which all outcomes are equally likely within a given range. It is one of the simplest probability distributions and can be either discrete or continuous.\n",
    "\n",
    "Uniform Distribution\n",
    "\n",
    "Continuous Uniform Distribution\n",
    "\n",
    "For a continuous uniform distribution, every value within a specified range [a,b] is equally likely. The probability density function (PDF) for a continuous uniform distribution is defined as:\n",
    "\n",
    "{1/(b-a) for a≤x≤b , 0 otherwise}\n",
    "\n",
    "Discrete Uniform Distribution\n",
    "\n",
    "In a discrete uniform distribution, a finite number of outcomes are equally likely. The probability mass function (PMF) is defined as:\n",
    "\n",
    "P(X=x)= 1/n\n",
    " \n",
    "\n",
    "for x=x1,x2,........,xn where n is the number of possible outcomes\n",
    "\n",
    "n is the number of possible outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dcbcf-f16a-40f5-bf90-d522be2de92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868e0408-282a-4cb0-88b7-4ff590915981",
   "metadata": {},
   "source": [
    "A Z score, also known as a standard score, is a statistical measure that describes a value's relationship to the mean of a group of values. The Z score is calculated by taking the difference between the value and the mean of the dataset and then dividing this difference by the standard deviation of the dataset.\n",
    "\n",
    "The formula for calculating the Z score is:\n",
    "Z=σ/(X−μ).\n",
    " \n",
    "where:\n",
    "\n",
    "X is the value in question,\n",
    "μ is the mean of the dataset,\n",
    "σ is the standard deviation of the dataset.\n",
    "\n",
    "Importance of the Z Score\n",
    "\n",
    "Standardization: The Z score standardizes different data points to a common scale with a mean of 0 and a standard deviation of 1. This standardization allows for comparison across different datasets and variables that may have different units or scales.\n",
    "\n",
    "Identifying Outliers: Z scores help in identifying outliers in the data. Typically, a Z score above 3 or below -3 is considered an outlier, indicating that the data point is far from the mean.\n",
    "\n",
    "Probability Calculations: Z scores are used to calculate probabilities in a normal distribution. By converting raw scores to Z scores, one can use standard normal distribution tables (Z tables) to find the probability of a value occurring within a particular range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc17ef3-944b-4451-b359-0fdea991a2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a225b1d-e024-4d0a-aa05-761428486bac",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental theorem in probability and statistics. It states that the distribution of the sum (or average) of a large number of independent, identically distributed (i.i.d.) random variables tends to be approximately normal, regardless of the original distribution of the variables. \n",
    "\n",
    "Significance of the Central Limit Theorem\n",
    "\n",
    "Foundation for Inferential Statistics:\n",
    "\n",
    "The CLT underpins many statistical methods and hypothesis tests. It allows statisticians to make inferences about population parameters using sample data.\n",
    "\n",
    "Approximation of Distributions:\n",
    "\n",
    "For large sample sizes, the distribution of the sample mean can be approximated by a normal distribution, even if the original data is not normally distributed. This is particularly useful in practical applications where the true distribution of the population is unknown.\n",
    "\n",
    "Simplification of Analysis:\n",
    "\n",
    "Many statistical procedures rely on the normality assumption. The CLT justifies the use of these procedures by ensuring that, for large enough sample sizes, the distribution of the sample mean is approximately normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265c0cf-0ac5-46e5-a990-03ac2bead5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54b020ca-dffb-4d2d-ad84-66a72b6980c2",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) relies on several key assumptions:\n",
    "\n",
    "Independence: The random variables being averaged or summed must be independent of each other. This means that the outcome of one variable should not influence the outcome of another.\n",
    "\n",
    "Identically Distributed: The random variables should be drawn from the same probability distribution. This ensures that they have the same mean and variance.\n",
    "\n",
    "Finite Variance: The random variables must have a finite variance. This ensures that the fluctuations of individual observations are not too extreme.\n",
    "\n",
    "Large Sample Size: The theorem holds as the sample size (n) tends to infinity. Although the exact threshold for \"large enough\" can vary depending on the context, a common rule of thumb is that n should be at least 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1cc79-dd12-4fcf-b6a1-1102c6319f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
